import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.output_parsers import StrOutputParser

# ============================================================================
# Chat Memory: ëŒ€í™”ì˜ ë§¥ë½(Context)ì„ ê¸°ì–µí•˜ëŠ” ì²´ì¸ ë§Œë“¤ê¸°
# ============================================================================
# ê¸°ë³¸ LLM ì²´ì¸ì€ Stateless(ë¬´ìƒíƒœ)ì…ë‹ˆë‹¤. ì¦‰, ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ì§€ ëª»í•¨.
# RunnableWithMessageHistoryë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ë‚´ì—­ì„ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì„ ë°°ì›€.
# ============================================================================

# load env
load_dotenv()

# LLM & Parser
llm = ChatOpenAI(model="gpt-4o-mini")
output_parser = StrOutputParser()

# 1. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
# MessagesPlaceholder: ëŒ€í™” ë‚´ì—­ì´ ë“¤ì–´ê°ˆ ìœ„ì¹˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
prompt = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤."),
    MessagesPlaceholder(variable_name="chat_history"),  # ëŒ€í™” ë‚´ì—­ì´ ì—¬ê¸°ì— ì£¼ì…ë¨
    ("human", "{input}")
])

# 2. ê¸°ë³¸ ì²´ì¸ ìƒì„±
chain = prompt | llm | output_parser

# 3. ëŒ€í™” ë‚´ì—­ ì €ì¥ì†Œ (ë©”ëª¨ë¦¬) ì„¤ì •
# ì„¸ì…˜ IDë³„ë¡œ ëŒ€í™” ë‚´ì—­ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
store = {}

def get_session_history(session_id: str):
    """ì„¸ì…˜ IDì— í•´ë‹¹í•˜ëŠ” ëŒ€í™” ë‚´ì—­ì„ ë°˜í™˜"""
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# 4. ë©”ëª¨ë¦¬ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ì²´ì¸ ìƒì„±
# RunnableWithMessageHistoryë¡œ ê¸°ì¡´ ì²´ì¸ì„ ë˜í•‘
chain_with_memory = RunnableWithMessageHistory(
    chain,
    get_session_history,
    input_messages_key="input",
    history_messages_key="chat_history",
)

# ============================================================================
# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
# ============================================================================

print("="*60)
print("ë©”ëª¨ë¦¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (ì„¸ì…˜ ID: user1)")
print("="*60)

# ì²« ë²ˆì§¸ ì§ˆë¬¸
query1 = "ë‚´ ì´ë¦„ì€ BMAPSì•¼."
print(f"\nğŸ‘¤ ì‚¬ìš©ì: {query1}")
response1 = chain_with_memory.invoke(
    {"input": query1},
    config={"configurable": {"session_id": "user1"}}
)
print(f"ğŸ¤– AI: {response1}")

# ë‘ ë²ˆì§¸ ì§ˆë¬¸ (ì´ì „ ëŒ€í™” ê¸°ì–µ í™•ì¸)
query2 = "ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?"
print(f"\nğŸ‘¤ ì‚¬ìš©ì: {query2}")
response2 = chain_with_memory.invoke(
    {"input": query2},
    config={"configurable": {"session_id": "user1"}}
)
print(f"ğŸ¤– AI: {response2}")

# ============================================================================
# ë‹¤ë¥¸ ì„¸ì…˜ í…ŒìŠ¤íŠ¸ (ê²©ë¦¬ í™•ì¸)
# ============================================================================

print("\n" + "="*60)
print("ë‹¤ë¥¸ ì„¸ì…˜ í…ŒìŠ¤íŠ¸ (ì„¸ì…˜ ID: user2)")
print("="*60)

# ë‹¤ë¥¸ ì„¸ì…˜ IDë¡œ ì§ˆë¬¸ (user1ì˜ ì •ë³´ë¥¼ ëª°ë¼ì•¼í•¨)
print(f"\nğŸ‘¤ ì‚¬ìš©ì (user2): {query2}")
response3 = chain_with_memory.invoke(
    {"input": query2},
    config={"configurable": {"session_id": "user2"}}
)
print(f"ğŸ¤– AI: {response3}")

