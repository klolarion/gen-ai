import os

from dotenv import load_dotenv
from langchain_community.vectorstores import Chroma
from langchain_core.example_selectors import SemanticSimilarityExampleSelector
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate, ChatPromptTemplate, \
    FewShotChatMessagePromptTemplate
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings


# load env
load_dotenv()

# API KEY
api_key = os.getenv("OPENAI_API_KEY")

# model
llm = ChatOpenAI(model="gpt-4o-mini", api_key=api_key, temperature=0.0)

# parser
output_parser = StrOutputParser()


# Few-shot: ì˜ˆì‹œë¥¼ ì œê³µí•˜ì—¬ LLMì´ ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ë„ë¡ ìœ ë„ (ê³ ì • ì˜ˆì‹œ ë˜ëŠ” ì˜ë¯¸ ìœ ì‚¬ë„ ê¸°ë°˜ ë™ì  ì„ íƒ)
# - LLMì—ê²Œ ëª‡ ê°€ì§€ ì˜ˆì‹œ(Q&A)ë¥¼ ì œê³µí•´, ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ë„ë¡ ìœ ë„í•˜ëŠ” ê¸°ë²•ì´ë‹¤.
# - í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ì§€ì‹ì´ë‚˜ íŒ¨í„´ ìœ ë„ì— ì£¼ë¡œ ì‚¬ìš©ëœë‹¤.

# ì‚¬ìš© ì˜ˆ:
# 1) ì§ˆë¬¸ í‘œí˜„ì€ ë‹¤ì–‘í•˜ì§€ë§Œ, ì •ë‹µì€ í•˜ë‚˜ë¡œ ê³ ì •ë˜ì–´ì•¼ í•  ë•Œ
# 2) ì™¸ë¶€ ê²€ìƒ‰ì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ ì—†ì´, í”„ë¡¬í”„íŠ¸ë§Œìœ¼ë¡œ ì •ë‹µì„ ìœ ë„í•˜ê³ ì í•  ë•Œ
# 3) ëª¨ë¸ì´ íŠ¹ì • ì§ˆë¬¸ì—ì„œ ì˜¤ë‹µì„ ì˜ ë‚¼ ê²½ìš°, ì˜ˆì‹œë¡œ ì˜¬ë°”ë¥¸ ë‹µë³€ í˜•ì‹ì„ êµì •í•  ë•Œ

# â†’ íŠ¹ì • ë„ë©”ì¸, ì§ˆë¬¸ í˜•ì‹, ì–´ì¡° ë“±ì—ì„œ ëª¨ë¸ì˜ ì¼ê´€ëœ ì„±ëŠ¥ í–¥ìƒì— íš¨ê³¼ì ì´ë‹¤.


# # Few-shot formatter
example_prompt1 = PromptTemplate.from_template("Q: {question}\nA: {answer}\n")
#
# ì˜ˆì œ ì„¸íŠ¸
examples1 = [
    {
        "question": "ì§€êµ¬ì˜ ëŒ€ê¸° ì¤‘ ê°€ì¥ ë§ì€ ê¸°ì²´ëŠ”?",
        "answer": "ì§€êµ¬ ëŒ€ê¸°ì˜ ì•½ 78%ë¥¼ ì°¨ì§€í•˜ëŠ” ì§ˆì†Œì…ë‹ˆë‹¤."
    },
    {
        "question": "ì§€êµ¬ ëŒ€ê¸° êµ¬ì„± ë¬¼ì§ˆ ì¤‘ ê°€ì¥ ë§ì€ ê²ƒì€?",
        "answer": "ì§€êµ¬ ëŒ€ê¸°ì˜ ì•½ 78%ë¥¼ ì°¨ì§€í•˜ëŠ” ì§ˆì†Œì…ë‹ˆë‹¤."
    },
    {
        "question": "ê³µê¸° ì¤‘ì— ê°€ì¥ ë§ì€ ê¸°ì²´ëŠ”?",
        "answer": "ì£¼ì„±ë¶„ì€ ì§ˆì†Œì´ë©°, ì´ëŠ” ì§€êµ¬ ëŒ€ê¸°ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•©ë‹ˆë‹¤"
    },
    {
        "question": "ê´‘í•©ì„±ì— í•„ìš”í•œ ì£¼ìš” ìš”ì†Œë“¤ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "answer": "ê´‘í•©ì„±ì— í•„ìš”í•œ ì£¼ìš” ìš”ì†ŒëŠ” ë¹›, ì´ì‚°í™”íƒ„ì†Œ, ë¬¼ì…ë‹ˆë‹¤."
    },
    {
        "question": "í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "answer": "í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ëŠ” ì§ê°ì‚¼ê°í˜•ì—ì„œ ë¹—ë³€ì˜ ì œê³±ì´ ë‹¤ë¥¸ ë‘ ë³€ì˜ ì œê³±ì˜ í•©ê³¼ ê°™ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤."
    },
    {
        "question": "ì§€êµ¬ì˜ ìì „ ì£¼ê¸°ëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
        "answer": "ì§€êµ¬ì˜ ìì „ ì£¼ê¸°ëŠ” ì•½ 24ì‹œê°„(ì •í™•íˆëŠ” 23ì‹œê°„ 56ë¶„ 4ì´ˆ)ì…ë‹ˆë‹¤."
    },
    {
        "question": "DNAì˜ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "answer": "DNAëŠ” ë‘ ê°œì˜ í´ë¦¬ë‰´í´ë ˆì˜¤í‹°ë“œ ì‚¬ìŠ¬ì´ ì´ì¤‘ ë‚˜ì„  êµ¬ì¡°ë¥¼ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤."
    },
    {
        "question": "ì›ì£¼ìœ¨(Ï€)ì˜ ì •ì˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "answer": "ì›ì£¼ìœ¨(Ï€)ì€ ì›ì˜ ì§€ë¦„ì— ëŒ€í•œ ì›ì˜ ë‘˜ë ˆì˜ ë¹„ìœ¨ì…ë‹ˆë‹¤."
    }
]
#
# prompt = FewShotPromptTemplate(
#     examples=examples1,                                # ì˜ˆì œ ë°ì´í„° ëª©ë¡
#     example_prompt=example_prompt1,                    # ê° ì˜ˆì œë¥¼ ì–´ë–¤ í˜•ì‹ìœ¼ë¡œ ë³´ì—¬ì¤„ì§€ ì •ì˜
#     prefix="ë‹¤ìŒì€ ê³¼í•™ê³¼ ìˆ˜í•™ ì§ˆë¬¸ì— ëŒ€í•œ ì˜ˆì‹œì…ë‹ˆë‹¤:",     # ì˜ˆì œ ì•ì— ì¶”ê°€ë  ì ‘ë¯¸ì‚¬ -> LLMì—ê²Œ ì˜ˆì œë¥¼ ì†Œê°œí•˜ëŠ” ë¬¸êµ¬
#     suffix="Q: {input}\nA:",                          # ì˜ˆì œ ë’¤ì— ì¶”ê°€ë  ì ‘ë¯¸ì‚¬ -> ì‹¤ì œ ì‚¬ìš©ì ì…ë ¥ ì§ˆë¬¸ì´ ë“¤ì–´ê°ˆ ìœ„ì¹˜
#     input_variables=["input"],                        # ìµœì¢… ì§ˆë¬¸ì—ì„œ ë“¤ì–´ì˜¬ ë³€ìˆ˜ëª…
# )
#
# chain = prompt | llm | output_parser
# result = chain.invoke({"input": "ì§€êµ¬ ê³µê¸°ì˜ ì£¼ ì„±ë¶„?"})
# print(result)

# # --------------------------------------------------------------------

# SemanticSimilarityExampleSelector
# # ì˜ë¯¸ì  ìœ ì‚¬ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì‘ë‹µì„ ì„ íƒí•˜ì—¬ ì‘ë‹µ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¨ë‹¤.
# example_selector1 = SemanticSimilarityExampleSelector.from_examples(
#     examples1,  # ì‚¬ìš©í•  ì˜ˆì œë“¤
#     OpenAIEmbeddings(),  # ì„ë² ë”© ëª¨ë¸
#     Chroma,  # ë²¡í„° ì €ì¥ì†Œ
#     k=1,  # ì„ íƒí•  ì˜ˆì œ ìˆ˜
# )



# ìƒˆë¡œìš´ ì§ˆë¬¸ì— ëŒ€í•´ ê°€ì¥ ìœ ì‚¬í•œ ì˜ˆì œë¥¼ ì„ íƒí•œë‹¤.
question = "í™”ì„±ì˜ ëŒ€ê¸° êµ¬ì¡°ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
# selected_examples1 = example_selector1.select_examples({"question": question})
# print(f"\nì…ë ¥ ì§ˆë¬¸: {question}")
# print("ìœ ì‚¬í•œ ì˜ˆì œ:")
# for ex in selected_examples1:
#     print(f"- {ex['question']} â†’ {ex['answer']}")


# prompt = FewShotPromptTemplate(
#     example_selector=example_selector1,                #
#     example_prompt=example_prompt1,                    # ê° ì˜ˆì œë¥¼ ì–´ë–¤ í˜•ì‹ìœ¼ë¡œ ë³´ì—¬ì¤„ì§€ ì •ì˜
#     prefix="ë‹¤ìŒì€ ê³¼í•™ê³¼ ìˆ˜í•™ ì§ˆë¬¸ì— ëŒ€í•œ ì˜ˆì‹œì…ë‹ˆë‹¤:",     # ì˜ˆì œ ì•ì— ì¶”ê°€ë  ì ‘ë¯¸ì‚¬ -> LLMì—ê²Œ ì˜ˆì œë¥¼ ì†Œê°œí•˜ëŠ” ë¬¸êµ¬
#     suffix="Q: {input}\nA:",                          # ì˜ˆì œ ë’¤ì— ì¶”ê°€ë  ì ‘ë¯¸ì‚¬ -> ì‹¤ì œ ì‚¬ìš©ì ì…ë ¥ ì§ˆë¬¸ì´ ë“¤ì–´ê°ˆ ìœ„ì¹˜
#     input_variables=["input"],                        # ìµœì¢… ì§ˆë¬¸ì—ì„œ ë“¤ì–´ì˜¬ ë³€ìˆ˜ëª…
# )

# prompt.format(input="í™”ì„±ì˜ ëŒ€ê¸° êµ¬ì¡°ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?")

## ì‹¤ì œ ì‹¤í–‰
# chain1 = prompt | llm | output_parser
# result = chain1.invoke({"input": question})
# print("\nğŸŸ¢ ìµœì¢… ì‘ë‹µ:")
# print(result)

# # --------------------------------------------------------------------

# Fixed Few-shot in ChatPrompt

# ì˜ˆì œ ì •ì˜
examples2 = [
    {"input": "ì§€êµ¬ì˜ ëŒ€ê¸° ì¤‘ ê°€ì¥ ë§ì€ ë¹„ìœ¨ì„ ì°¨ì§€í•˜ëŠ” ê¸°ì²´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?", "output": "ì§ˆì†Œì…ë‹ˆë‹¤."},
    {"input": "ê´‘í•©ì„±ì— í•„ìš”í•œ ì£¼ìš” ìš”ì†Œë“¤ì€ ë¬´ì—‡ì¸ê°€ìš”?", "output": "ë¹›, ì´ì‚°í™”íƒ„ì†Œ, ë¬¼ì…ë‹ˆë‹¤."},
]

# ì˜ˆì œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
example_prompt2 = ChatPromptTemplate.from_messages(
    [
        ("human", "{input}"),
        ("ai", "{output}"),
    ]
)

# Few-shot í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
few_shot_prompt2 = FewShotChatMessagePromptTemplate(
    example_prompt=example_prompt2,
    examples=examples2,
)

# ìµœì¢… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
final_prompt2 = ChatPromptTemplate.from_messages(
    [
        ("system", "ë‹¹ì‹ ì€ ê³¼í•™ê³¼ ìˆ˜í•™ì— ëŒ€í•´ ì˜ ì•„ëŠ” êµìœ¡ìì…ë‹ˆë‹¤."),
        few_shot_prompt2,
        ("human", "{input}"),
    ]
)

# chain2 = final_prompt2 | llm
# result = chain2.invoke({"input": "ì§€êµ¬ì˜ ìì „ ì£¼ê¸°ëŠ” ì–¼ë§ˆì¸ê°€ìš”?"})
# print(result.content)




# Dynamic Few-shot in ChatPrompt

# SemanticSimilarityExampleSelectorëŠ” ì…ë ¥ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì˜ˆì‹œ kê°œë¥¼ ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ì„ íƒí•œë‹¤.
# ì„ íƒëœ ì˜ˆì‹œëŠ” ChatPromptTemplate í˜•ì‹ìœ¼ë¡œ í¬ë§·ë˜ì–´, ì‹¤ì œ ì‚¬ìš©ì ì§ˆë¬¸ ì „ì— LLMì—ê²Œ íŒíŠ¸ë¡œ ì œê³µëœë‹¤.

# ë” ë§ì€ ì˜ˆì œ ì¶”ê°€
examples3 = [
    {"input": "ì§€êµ¬ì˜ ëŒ€ê¸° ì¤‘ ê°€ì¥ ë§ì€ ë¹„ìœ¨ì„ ì°¨ì§€í•˜ëŠ” ê¸°ì²´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?", "output": "ì§ˆì†Œì…ë‹ˆë‹¤."},
    {"input": "ê´‘í•©ì„±ì— í•„ìš”í•œ ì£¼ìš” ìš”ì†Œë“¤ì€ ë¬´ì—‡ì¸ê°€ìš”?", "output": "ë¹›, ì´ì‚°í™”íƒ„ì†Œ, ë¬¼ì…ë‹ˆë‹¤."},
    {"input": "í”¼íƒ€ê³ ë¼ìŠ¤ ì •ë¦¬ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.", "output": "ì§ê°ì‚¼ê°í˜•ì—ì„œ ë¹—ë³€ì˜ ì œê³±ì€ ë‹¤ë¥¸ ë‘ ë³€ì˜ ì œê³±ì˜ í•©ê³¼ ê°™ìŠµë‹ˆë‹¤."},
    {"input": "DNAì˜ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.", "output": "DNAëŠ” ì´ì¤‘ ë‚˜ì„  êµ¬ì¡°ë¥¼ ê°€ì§„ í•µì‚°ì…ë‹ˆë‹¤."},
    {"input": "ì›ì£¼ìœ¨(Ï€)ì˜ ì •ì˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?", "output": "ì›ì˜ ë‘˜ë ˆì™€ ì§€ë¦„ì˜ ë¹„ìœ¨ì…ë‹ˆë‹¤."},
]

# ë²¡í„° ì €ì¥ì†Œ ìƒì„±
to_vectorize = [" ".join(example.values()) for example in examples3]
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples3)

# ì˜ˆì œ ì„ íƒê¸° ìƒì„±
example_selector3 = SemanticSimilarityExampleSelector(
    vectorstore=vectorstore,
    k=2,
)

# Few-shot í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
few_shot_prompt3 = FewShotChatMessagePromptTemplate(
    example_selector=example_selector3,
    example_prompt=ChatPromptTemplate.from_messages(
        [("human", "{input}"), ("ai", "{output}")]
    ),
)

# ìµœì¢… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
final_prompt3 = ChatPromptTemplate.from_messages(
    [
        ("system", "ë‹¹ì‹ ì€ ê³¼í•™ê³¼ ìˆ˜í•™ì— ëŒ€í•´ ì˜ ì•„ëŠ” êµìœ¡ìì…ë‹ˆë‹¤."),
        few_shot_prompt3,
        ("human", "{input}"),
    ]
)

# ëª¨ë¸ê³¼ ì²´ì¸ ìƒì„±
chain3 = final_prompt3 | llm

# ëª¨ë¸ì— ì§ˆë¬¸í•˜ê¸°
result = chain3.invoke({"input": "íƒœì–‘ê³„ì—ì„œ ê°€ì¥ í° í–‰ì„±ì€ ë¬´ì—‡ì¸ê°€ìš”?"})
print(result.content)