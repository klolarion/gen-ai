import os
import time
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser

# ============================================================================
# RunnableParallel: ì—¬ëŸ¬ ì‘ì—…ì„ ë™ì‹œì— ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ê¸°
# ============================================================================
# í•˜ë‚˜ì˜ ì…ë ¥ì— ëŒ€í•´ ì—¬ëŸ¬ ê°€ì§€ ì²˜ë¦¬(ì˜ˆ: ìš”ì•½, ë²ˆì—­, ë¶„ì„)ë¥¼ ë™ì‹œì— ìˆ˜í–‰í•  ë•Œ ì‚¬ìš©í•œë‹¤.
# ì²˜ë¦¬ ì‹œê°„ì„ ë‹¨ì¶•í•˜ê³  ë‹¤ì–‘í•œ ê´€ì ì˜ ê²°ê³¼ë¥¼ í•œ ë²ˆì— ì–»ì„ ìˆ˜ ìˆë‹¤.
# ============================================================================

# load env
load_dotenv()

# LLM
llm = ChatOpenAI(model="gpt-4o-mini")
output_parser = StrOutputParser()

# ì‹œê°„ ì¸¡ì • ë° ë¡œê¹…ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜
def log_execution_time(chain_name):
    def wrapper(input_data):
        start_time = time.time()
        print(f"ğŸš€ [{chain_name}] ì‹œì‘: {time.strftime('%H:%M:%S')}")
        
        # ì‹¤ì œ ì²´ì¸ ì‹¤í–‰ (ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ í˜¸ì¶œì„ í‰ë‚´ë‚´ê¸° ìœ„í•´ input_dataë¥¼ ê·¸ëŒ€ë¡œ ë„˜ê¹€)
        # ì‹¤ì œë¡œëŠ” ì´ ë˜í¼ê°€ ì²´ì¸ ë‚´ë¶€ì—ì„œ ì‚¬ìš©ëœë‹¤.
        return input_data
    return wrapper

# 1. ê°œë³„ ì²´ì¸ ì •ì˜
# ê° ì²´ì¸ì˜ ì‹¤í–‰ ì‹œê°„ì„ í™•ì¸í•˜ê¸° ìœ„í•´ RunnableLambdaë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œê¹… ì¶”ê°€

# ì²´ì¸ A: ì£¼ì œì— ëŒ€í•œ 'ì¥ì ' ë¶„ì„
pros_prompt = ChatPromptTemplate.from_template("{topic}ì˜ ì¥ì ì„ 3ê°€ì§€ ìš”ì•½í•´ì¤˜.")
# ë¡œê¹…ì„ ìœ„í•´ ì»¤ìŠ¤í…€ í•¨ìˆ˜ ì¶”ê°€
pros_chain = (
    RunnableLambda(lambda x: (print(f"ğŸš€ [ì¥ì  ë¶„ì„] ì‹œì‘: {time.strftime('%H:%M:%S')}"), x)[1])
    | pros_prompt 
    | llm 
    | output_parser
    | RunnableLambda(lambda x: (print(f"âœ… [ì¥ì  ë¶„ì„] ì™„ë£Œ: {time.strftime('%H:%M:%S')}"), x)[1])
)

# ì²´ì¸ B: ì£¼ì œì— ëŒ€í•œ 'ë‹¨ì ' ë¶„ì„
cons_prompt = ChatPromptTemplate.from_template("{topic}ì˜ ë‹¨ì ì„ 3ê°€ì§€ ìš”ì•½í•´ì¤˜.")
cons_chain = (
    RunnableLambda(lambda x: (print(f"ğŸš€ [ë‹¨ì  ë¶„ì„] ì‹œì‘: {time.strftime('%H:%M:%S')}"), x)[1])
    | cons_prompt 
    | llm 
    | output_parser
    | RunnableLambda(lambda x: (print(f"âœ… [ë‹¨ì  ë¶„ì„] ì™„ë£Œ: {time.strftime('%H:%M:%S')}"), x)[1])
)

# ì²´ì¸ C: ì£¼ì œë¡œ 'ì‹œ' ì‘ì„±
poem_prompt = ChatPromptTemplate.from_template("{topic}ë¥¼ ì£¼ì œë¡œ ì§§ì€ ì‹œë¥¼ ì¨ì¤˜.")
poem_chain = (
    RunnableLambda(lambda x: (print(f"ğŸš€ [ì‹œ  ì‘ì„±] ì‹œì‘: {time.strftime('%H:%M:%S')}"), x)[1])
    | poem_prompt 
    | llm 
    | output_parser
    | RunnableLambda(lambda x: (print(f"âœ… [ì‹œ  ì‘ì„±] ì™„ë£Œ: {time.strftime('%H:%M:%S')}"), x)[1])
)

# 2. ë³‘ë ¬ ì²´ì¸ êµ¬ì„± (RunnableParallel)
# ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ê° ì‘ì—…ì˜ í‚¤ì™€ ì‹¤í–‰í•  ì²´ì¸ì„ ì§€ì •
parallel_chain = RunnableParallel(
    pros=pros_chain,
    cons=cons_chain,
    poem=poem_chain,
    original_topic=RunnablePassthrough()  # ì›ë³¸ ì…ë ¥ë„ ê·¸ëŒ€ë¡œ í†µê³¼ì‹œì¼œ ê²°ê³¼ì— í¬í•¨
)

# ============================================================================
# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
# ============================================================================

topic = "ì¬íƒê·¼ë¬´"

print("="*60)
print(f"ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (ì£¼ì œ: {topic})")
print("ì¥ì  ë¶„ì„, ë‹¨ì  ë¶„ì„, ì‹œ ì‘ì„±ì„ ë™ì‹œì— ìˆ˜í–‰í•©ë‹ˆë‹¤...")
print(f"ì „ì²´ ì‹œì‘ ì‹œê°„: {time.strftime('%H:%M:%S')}")
print("="*60)

start_total = time.time()

# invoke í•œ ë²ˆìœ¼ë¡œ 3ê°€ì§€ ì‘ì—…ì´ ë³‘ë ¬ ì‹¤í–‰ë¨
result = parallel_chain.invoke({"topic": topic})

end_total = time.time()

print("\n" + "="*60)
print(f"ì „ì²´ ì™„ë£Œ ì‹œê°„: {time.strftime('%H:%M:%S')}")
print(f"ì´ ì†Œìš” ì‹œê°„: {end_total - start_total:.2f}ì´ˆ")
print("="*60)

# ê²°ê³¼ ì¶œë ¥
print("\n[1. ì¥ì  ë¶„ì„]")
print(result['pros'])

print("\n[2. ë‹¨ì  ë¶„ì„]")
print(result['cons'])

print("\n[3. ì‹œ ì‘ì„±]")
print(result['poem'])

print("\n[4. ì›ë³¸ ë°ì´í„°]")
print(result['original_topic'])

