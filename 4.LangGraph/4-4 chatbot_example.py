import os
from typing import TypedDict, Annotated, Literal
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

# load env
load_dotenv()

# API KEY
api_key = os.getenv("OPENAI_API_KEY")

# model
llm = ChatOpenAI(model="gpt-4o-mini", api_key=api_key, temperature=0.7)


# ============================================================================
# ì‹¤ì „ ì˜ˆì œ: ëŒ€í™”í˜• ì±—ë´‡ êµ¬í˜„
# ============================================================================
# ì´ ì˜ˆì œëŠ” LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì™„ì „í•œ ëŒ€í™”í˜• ì±—ë´‡ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
# íŠ¹ì§•:
# 1. ëŒ€í™” ê¸°ë¡ ìœ ì§€
# 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ì±—ë´‡ ì—­í•  ì„¤ì •
# 3. ì¡°ê±´ë¶€ ë¼ìš°íŒ…ìœ¼ë¡œ ëŒ€í™” ì¢…ë£Œ ê°ì§€
# 4. ìƒíƒœ ê´€ë¦¬ë¡œ ëŒ€í™” í„´ ì¶”ì 
# ============================================================================


class ChatbotState(TypedDict):
    """
    ì±—ë´‡ ìƒíƒœ êµ¬ì¡°
    
    messages: ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ (ìë™ ë³‘í•©)
    turn_count: í˜„ì¬ ëŒ€í™” í„´ ìˆ˜
    should_end: ëŒ€í™” ì¢…ë£Œ ì—¬ë¶€
    """
    messages: Annotated[list, add_messages]
    turn_count: int
    should_end: bool


# ============================================================================
# ë…¸ë“œ í•¨ìˆ˜ë“¤
# ============================================================================

def initialize_chat(state: ChatbotState) -> ChatbotState:
    """
    ì±—ë´‡ ì´ˆê¸°í™” ë…¸ë“œ
    - ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ì—¬ ì±—ë´‡ì˜ ì—­í•  ì„¤ì •
    - turn_count ì´ˆê¸°í™”
    
    Args:
        state: í˜„ì¬ ìƒíƒœ
    
    Returns:
        ì´ˆê¸°í™”ëœ ìƒíƒœ
    """
    system_message = SystemMessage(
        content="ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
                "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. "
                "í•œêµ­ì–´ë¡œ ëŒ€í™”í•©ë‹ˆë‹¤."
    )
    
    return {
        "messages": [system_message],
        "turn_count": 0,
        "should_end": False
    }


def check_should_end(state: ChatbotState) -> ChatbotState:
    """
    ëŒ€í™” ì¢…ë£Œ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” ë…¸ë“œ
    - ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ì¢…ë£Œ í‚¤ì›Œë“œ í™•ì¸
    
    Args:
        state: í˜„ì¬ ìƒíƒœ
    
    Returns:
        should_end í”Œë˜ê·¸ê°€ ì„¤ì •ëœ ìƒíƒœ
    """
    messages = state["messages"]
    
    # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë©”ì‹œì§€ ì°¾ê¸°
    last_user_message = None
    for msg in reversed(messages):
        if isinstance(msg, HumanMessage):
            last_user_message = msg.content.lower()
            break
    
    # ì¢…ë£Œ í‚¤ì›Œë“œ í™•ì¸
    end_keywords = ["ì¢…ë£Œ", "ë", "ê·¸ë§Œ", "bye", "ì•ˆë…•íˆ", "ë‚˜ê°€ê¸°", "exit", "quit"]
    should_end = any(keyword in last_user_message for keyword in end_keywords) if last_user_message else False
    
    return {"should_end": should_end}


def generate_response(state: ChatbotState) -> ChatbotState:
    """
    AI ì‘ë‹µ ìƒì„± ë…¸ë“œ
    - ì „ì²´ ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•˜ì—¬ LLM í˜¸ì¶œ
    - turn_count ì¦ê°€
    
    Args:
        state: í˜„ì¬ ìƒíƒœ
    
    Returns:
        AI ì‘ë‹µì´ ì¶”ê°€ë˜ê³  turn_countê°€ ì¦ê°€í•œ ìƒíƒœ
    """
    messages = state["messages"]
    turn_count = state.get("turn_count", 0)
    
    # LLM í˜¸ì¶œ (ì „ì²´ ëŒ€í™” ê¸°ë¡ í¬í•¨)
    response = llm.invoke(messages)
    
    return {
        "messages": [response],
        "turn_count": turn_count + 1
    }


def handle_goodbye(state: ChatbotState) -> ChatbotState:
    """
    ì‘ë³„ ì¸ì‚¬ ë…¸ë“œ
    - ëŒ€í™” ì¢…ë£Œ ì‹œ ì‘ë³„ ë©”ì‹œì§€ ì¶”ê°€
    
    Args:
        state: í˜„ì¬ ìƒíƒœ
    
    Returns:
        ì‘ë³„ ë©”ì‹œì§€ê°€ ì¶”ê°€ëœ ìƒíƒœ
    """
    goodbye_message = AIMessage(
        content="ëŒ€í™”í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ë˜ ë§Œë‚˜ìš”! ğŸ‘‹"
    )
    
    return {"messages": [goodbye_message]}


# ============================================================================
# ì¡°ê±´ë¶€ ë¼ìš°íŒ… í•¨ìˆ˜
# ============================================================================

def route_after_check(state: ChatbotState) -> Literal["generate", "goodbye", END]:
    """
    ì¢…ë£Œ í™•ì¸ í›„ ë¼ìš°íŒ… í•¨ìˆ˜
    
    Args:
        state: í˜„ì¬ ìƒíƒœ
    
    Returns:
        ë‹¤ìŒ ë…¸ë“œ ì´ë¦„
    """
    if state.get("should_end", False):
        return "goodbye"
    else:
        return "generate"


def route_after_response(state: ChatbotState) -> Literal["check_end", END]:
    """
    ì‘ë‹µ ìƒì„± í›„ ë¼ìš°íŒ… í•¨ìˆ˜
    
    Args:
        state: í˜„ì¬ ìƒíƒœ
    
    Returns:
        ë‹¤ìŒ ë…¸ë“œ ì´ë¦„
    """
    # ëŒ€í™”ê°€ ë„ˆë¬´ ê¸¸ë©´ ì¢…ë£Œ (ì˜ˆ: 10í„´ ì´ìƒ)
    if state.get("turn_count", 0) >= 10:
        return END
    
    return "check_end"


# ============================================================================
# ê·¸ë˜í”„ êµ¬ì„±
# ============================================================================

workflow = StateGraph(ChatbotState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("init", initialize_chat)
workflow.add_node("check_end", check_should_end)
workflow.add_node("generate", generate_response)
workflow.add_node("goodbye", handle_goodbye)

# ì—£ì§€ ì„¤ì •
workflow.set_entry_point("init")
workflow.add_edge("init", "check_end")

# ì¡°ê±´ë¶€ ì—£ì§€: ì¢…ë£Œ í™•ì¸ í›„ ë¶„ê¸°
workflow.add_conditional_edges(
    "check_end",
    route_after_check,
    {
        "generate": "generate",
        "goodbye": "goodbye",
        END: END
    }
)

# ì¡°ê±´ë¶€ ì—£ì§€: ì‘ë‹µ ìƒì„± í›„ ë¶„ê¸°
workflow.add_conditional_edges(
    "generate",
    route_after_response,
    {
        "check_end": "check_end",
        END: END
    }
)

# ì‘ë³„ ì¸ì‚¬ í›„ ì¢…ë£Œ
workflow.add_edge("goodbye", END)

# ê·¸ë˜í”„ ì»´íŒŒì¼
app = workflow.compile()


# ============================================================================
# ëŒ€í™”í˜• ì‹¤í–‰ í•¨ìˆ˜
# ============================================================================

def run_chatbot():
    """
    ëŒ€í™”í˜• ì±—ë´‡ ì‹¤í–‰ í•¨ìˆ˜
    - ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ê·¸ë˜í”„ ì‹¤í–‰
    - ëŒ€í™” ê¸°ë¡ ìœ ì§€
    """
    print("=" * 80)
    print("LangGraph ì±—ë´‡ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ', 'ë', 'ê·¸ë§Œ' ë“±ì„ ì…ë ¥í•˜ì„¸ìš”.")
    print("=" * 80)
    print()
    
    # ì´ˆê¸° ìƒíƒœ
    current_state = {
        "messages": [],
        "turn_count": 0,
        "should_end": False
    }
    
    # ì´ˆê¸°í™” ì‹¤í–‰
    current_state = app.invoke(current_state)
    
    # ì´ˆê¸° ì¸ì‚¬ ë©”ì‹œì§€ ì¶œë ¥
    for message in current_state["messages"]:
        if isinstance(message, AIMessage):
            print(f"[ì±—ë´‡]: {message.content}")
            print()
    
    # ëŒ€í™” ë£¨í”„
    while not current_state.get("should_end", False) and current_state.get("turn_count", 0) < 10:
        # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        user_input = input("[ì‚¬ìš©ì]: ").strip()
        
        if not user_input:
            continue
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        current_state["messages"].append(HumanMessage(content=user_input))
        
        # ê·¸ë˜í”„ ì‹¤í–‰ ë°©ì‹ 1: ë…¸ë“œ í•¨ìˆ˜ ì§ì ‘ í˜¸ì¶œ (ê°„ë‹¨í•œ ë°©ì‹)
        # ì£¼ì˜: ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ê·¸ë˜í”„ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ê±°ë‚˜ ìŠ¤íŠ¸ë¦¼ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤
        # ì—¬ê¸°ì„œëŠ” í•™ìŠµ ëª©ì ìœ¼ë¡œ ë…¸ë“œ í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤
        
        # check_end ë…¸ë“œ ì‹¤í–‰
        check_result = check_should_end(current_state)
        current_state.update(check_result)
        
        if current_state.get("should_end", False):
            # goodbye ë…¸ë“œ ì‹¤í–‰
            goodbye_result = handle_goodbye(current_state)
            current_state.update(goodbye_result)
            print(f"[ì±—ë´‡]: {current_state['messages'][-1].content}")
            break
        
        # generate ë…¸ë“œ ì‹¤í–‰
        generate_result = generate_response(current_state)
        current_state.update(generate_result)
        
        # AI ì‘ë‹µ ì¶œë ¥
        print(f"[ì±—ë´‡]: {current_state['messages'][-1].content}")
        print()
    
    print("\nëŒ€í™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")


# ============================================================================
# ë‹¨ì¼ ì‹¤í–‰ ì˜ˆì œ (ëŒ€í™”í˜• ì•„ë‹˜)
# ============================================================================

def run_single_example():
    """
    ë‹¨ì¼ ë©”ì‹œì§€ë¡œ ê·¸ë˜í”„ ì‹¤í–‰ ì˜ˆì œ
    """
    print("\n" + "=" * 80)
    print("ë‹¨ì¼ ì‹¤í–‰ ì˜ˆì œ")
    print("=" * 80)
    
    initial_state = {
        "messages": [HumanMessage(content="ì•ˆë…•í•˜ì„¸ìš”! íŒŒì´ì¬ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.")],
        "turn_count": 0,
        "should_end": False
    }
    
    result = app.invoke(initial_state)
    
    print("\nëŒ€í™” ë‚´ìš©:")
    print("-" * 80)
    for message in result["messages"]:
        if isinstance(message, SystemMessage):
            print(f"[ì‹œìŠ¤í…œ]: {message.content[:50]}...")
        elif isinstance(message, HumanMessage):
            print(f"[ì‚¬ìš©ì]: {message.content}")
        elif isinstance(message, AIMessage):
            print(f"[ì±—ë´‡]: {message.content}")
    print("-" * 80)
    print(f"\nì´ ëŒ€í™” í„´: {result.get('turn_count', 0)}")


# ============================================================================
# ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    # ë‹¨ì¼ ì‹¤í–‰ ì˜ˆì œ
    run_single_example()
    
    # ëŒ€í™”í˜• ì‹¤í–‰ (ì£¼ì„ í•´ì œí•˜ì—¬ ì‚¬ìš©)
    # run_chatbot()


# ============================================================================
# ì°¸ê³ : ê°œì„  ì‚¬í•­
# ============================================================================
# 1. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ: LLM ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°
# 2. ë©”ëª¨ë¦¬ ê´€ë¦¬: ëŒ€í™”ê°€ ê¸¸ì–´ì§ˆ ë•Œ ì˜¤ë˜ëœ ë©”ì‹œì§€ ì œê±°
# 3. ì—ëŸ¬ ì²˜ë¦¬: LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§
# 4. ë¡œê¹…: ëŒ€í™” ê¸°ë¡ì„ íŒŒì¼ë¡œ ì €ì¥
# 5. ë©€í‹° ì—ì´ì „íŠ¸: ì—¬ëŸ¬ ì „ë¬¸ ì—ì´ì „íŠ¸ë¥¼ ì¡°í•©
# 6. ë„êµ¬ ì‚¬ìš©: ì™¸ë¶€ API, ê³„ì‚°ê¸° ë“± ë„êµ¬ í˜¸ì¶œ
# ============================================================================

