import os
import tiktoken
from dotenv import load_dotenv
from openai import OpenAI

# ============================================================================
# Token Counting: API ë¹„ìš© ì˜ˆì¸¡ ë° ì»¨í…ìŠ¤íŠ¸ ì œí•œ ê´€ë¦¬
# ============================================================================
# LLMì€ ë‹¨ì–´ê°€ ì•„ë‹Œ 'í† í°(Token)' ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•œë‹¤.
# API ë¹„ìš©ì€ í† í° ìˆ˜ì— ë¹„ë¡€í•˜ë©°, ëª¨ë¸ë§ˆë‹¤ ì²˜ë¦¬ ê°€ëŠ¥í•œ ìµœëŒ€ í† í° ìˆ˜ê°€ ì •í•´ì ¸ ìˆìŒ.
# tiktoken ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì„ ë°°ì›€.
# ============================================================================

# load env
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def num_tokens_from_string(string: str, model_name: str) -> int:
    """ì£¼ì–´ì§„ ë¬¸ìì—´ì˜ í† í° ìˆ˜ë¥¼ ë°˜í™˜í•œë‹¤."""
    try:
        # ëª¨ë¸ì— ë§ëŠ” ì¸ì½”ë”© ë°©ì‹ ë¡œë“œ
        encoding = tiktoken.encoding_for_model(model_name)
    except KeyError:
        # ëª¨ë¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ê¸°ë³¸ ì¸ì½”ë”©(cl100k_base) ì‚¬ìš© (GPT-4, GPT-3.5ìš©)
        print("Warning: model not found. Using cl100k_base encoding.")
        encoding = tiktoken.get_encoding("cl100k_base")
    
    num_tokens = len(encoding.encode(string))
    return num_tokens

# í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸
texts = [
    "Hello, world!",  # ì˜ì–´ (ì§§ìŒ)
    "ì•ˆë…•í•˜ì„¸ìš”, ë°˜ê°‘ìŠµë‹ˆë‹¤.",  # í•œêµ­ì–´ (í† í° ìˆ˜ê°€ ë” ë§ì´ ë‚˜ì˜´)
    "Python is an interpreted, high-level, general-purpose programming language."  # ì˜ì–´ (ê¸º)
]

# ëª¨ë¸ë³„ í† í° ê³„ì‚° í…ŒìŠ¤íŠ¸
models = ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"]

print("="*60)
print("í† í° ìˆ˜ ê³„ì‚° í…ŒìŠ¤íŠ¸")
print("="*60)

for text in texts:
    print(f"\nğŸ“ í…ìŠ¤íŠ¸: '{text}'")
    for model in models:
        token_count = num_tokens_from_string(text, model)
        print(f"   - [{model}]: {token_count} tokens")

# ============================================================================
# ì‹¤ë¬´ í™œìš© ì˜ˆì‹œ: ì˜ˆì‚°ì— ë§ì¶° í…ìŠ¤íŠ¸ ìë¥´ê¸°
# ============================================================================
print("\n" + "="*60)
print("í™œìš© ì˜ˆì‹œ: ìµœëŒ€ í† í° ì œí•œ (Truncation)")
print("="*60)

long_text = "ë°ì´í„° ë¶„ì„ê³¼ ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì´ ë°œì „í•¨ì— ë”°ë¼... " * 100  # ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸
max_limit = 50
model_name = "gpt-4o-mini"

encoding = tiktoken.encoding_for_model(model_name)
tokens = encoding.encode(long_text)

print(f"ì›ë³¸ í…ìŠ¤íŠ¸ í† í° ìˆ˜: {len(tokens)}")

if len(tokens) > max_limit:
    # í† í° ë‹¨ìœ„ë¡œ ìë¥´ê¸°
    truncated_tokens = tokens[:max_limit]
    truncated_text = encoding.decode(truncated_tokens)
    print(f"\n{max_limit} í† í°ìœ¼ë¡œ ìë¥¸ í…ìŠ¤íŠ¸:\n{truncated_text}...")
    print(f"(ì‹¤ì œ ë¹„ìš© ì²­êµ¬ ê¸°ì¤€ì€ ì´ ì˜ë¦° í…ìŠ¤íŠ¸ê°€ ëœë‹¤.)")
else:
    print("í…ìŠ¤íŠ¸ê°€ ì œí•œë³´ë‹¤ ì§§ìŒ.")

